{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c567d3bf",
   "metadata": {},
   "source": [
    "# Notebook to define ensemble for production, cm level\n",
    "Version developed for the UK FCDO\n",
    "## Including ensemble weighting\n",
    "\n",
    "This notebook defines the ensemble used for production: selects a set of pre-trained models, retrieves and calibrates them, computes weights, and computes and stores the ensemble model predictions.\n",
    "\n",
    "Models are stored in model storage and most of them specified in the notebook fat_cm_constituentmodels\n",
    "\n",
    "The notebook draws on the following files in this repository:\n",
    "\n",
    "Ensembling.py\n",
    "ModelList_cm_{dev_id}.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3f0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "# Views 3\n",
    "from viewser.operations import fetch\n",
    "from viewser import Queryset, Column\n",
    "import views_runs\n",
    "from views_partitioning import data_partitioner, legacy\n",
    "from stepshift import views\n",
    "import views_dataviz\n",
    "from views_runs import storage, ModelMetadata\n",
    "from views_runs.storage import store, retrieve, list, fetch_metadata\n",
    "from views_forecasts.extensions import *\n",
    "# Other packages\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e8c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages from Predicting Fatalies repository\n",
    "\n",
    "from HurdleRegression import *\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "from FetchData import FetchData, RetrieveFromList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89992da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities001'\n",
    "run_id = 'Fat_devel_v7'\n",
    "FutureStart = 506\n",
    "RunGeneticAlgo = False\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9465ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 15 fat_baseline_rf /Users/havardhegre/Pickles/Model_cm_fat_baseline_rf_fat_devel_v7.p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/havardhegre/anaconda3/envs/viewser/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model Algorithm_text is missing, left blank\n",
      "1 / 15 fat_conflicthistory_rf /Users/havardhegre/Pickles/Model_cm_fat_conflicthistory_rf_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "2 / 15 fat_conflicthistory_gbm /Users/havardhegre/Pickles/Model_cm_fat_conflicthistory_gbm_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "3 / 15 fat_conflicthistory_hurdle_lgb /Users/havardhegre/Pickles/Model_cm_fat_conflicthistory_hurdle_lgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "4 / 15 fat_conflicthistory_long_rf /Users/havardhegre/Pickles/Model_cm_fat_conflicthistory_long_rf_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "5 / 15 fat_vdem_hurdle_xgb /Users/havardhegre/Pickles/Model_cm_fat_vdem_hurdle_xgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "6 / 15 fat_wdi_rf /Users/havardhegre/Pickles/Model_cm_fat_wdi_rf_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "7 / 15 fat_topics_rf /Users/havardhegre/Pickles/Model_cm_fat_topics_rf_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "8 / 15 fat_topics_histgbm /Users/havardhegre/Pickles/Model_cm_fat_topics_histgbm_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "9 / 15 fat_broad_xgb /Users/havardhegre/Pickles/Model_cm_fat_broad_xgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "10 / 15 fat_greatest_hits_hurdle_xgb /Users/havardhegre/Pickles/Model_cm_fat_greatest_hits_hurdle_xgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "11 / 15 fat_hh20_hurdle_lgb /Users/havardhegre/Pickles/Model_cm_fat_hh20_hurdle_lgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "12 / 15 fat_all_pca3_xgb /Users/havardhegre/Pickles/Model_cm_fat_all_pca3_xgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "13 / 15 fat_topics_pca3_lgb /Users/havardhegre/Pickles/Model_cm_fat_topics_pca3_lgb_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "14 / 15 fat_hh20_Markov_glm /Users/havardhegre/Pickles/Model_cm_fat_hh20_Markov_glm_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n",
      "15 / 15 fat_hh20_Markov_rf /Users/havardhegre/Pickles/Model_cm_fat_hh20_Markov_rf_fat_devel_v7.p\n",
      "model Algorithm_text is missing, left blank\n"
     ]
    }
   ],
   "source": [
    "# Defining the ensemble\n",
    "# First item in dictionary is model name, second run id for development run\n",
    "ModelsToRead = [\n",
    "    ['fat_baseline_rf','fat_devel_v7'],\n",
    "    ['fat_conflicthistory_rf','fat_devel_v7'],\n",
    "    ['fat_conflicthistory_gbm','fat_devel_v7'],\n",
    "    ['fat_conflicthistory_hurdle_lgb','fat_devel_v7'],\n",
    "    ['fat_conflicthistory_long_rf','fat_devel_v7'],\n",
    "    ['fat_vdem_hurdle_xgb','fat_devel_v7'],\n",
    "    ['fat_wdi_rf','fat_devel_v7'],\n",
    "    ['fat_topics_rf','fat_devel_v7'],\n",
    "    ['fat_topics_histgbm','fat_devel_v7'],\n",
    "    ['fat_broad_xgb','fat_devel_v7'],\n",
    "    ['fat_greatest_hits_hurdle_xgb','fat_devel_v7'],\n",
    "    ['fat_hh20_hurdle_lgb','fat_devel_v7'],\n",
    "    ['fat_all_pca3_xgb','fat_devel_v7'],\n",
    "    ['fat_topics_pca3_lgb','fat_devel_v7'],\n",
    "    ['fat_hh20_Markov_glm','fat_devel_v7'],\n",
    "    ['fat_hh20_Markov_rf','fat_devel_v7'],\n",
    "]\n",
    "\n",
    "ModelList = []\n",
    "localpath = '/Users/havardhegre/Pickles/'\n",
    "i = 0\n",
    "for item in ModelsToRead:\n",
    "    picklename = localpath + 'Model_cm_' + item[0] + '_'+ item[1] + '.p'\n",
    "    print(i, '/', (len(ModelsToRead)-1), item[0],picklename)\n",
    "    trained_model = pkl.load( open (picklename, \"rb\") )\n",
    "    model = {\n",
    "        'modelname': trained_model['modelname'],\n",
    "        'depvar': trained_model['depvar'],\n",
    "        'data_train': trained_model['data_train'],\n",
    "        'queryset': trained_model['queryset'],\n",
    "        'algorithm': trained_model['algorithm'],\n",
    "        'Algorithm_text': \"\",\n",
    "#        'predstore_calib': trained_model['predstore_calib'],\n",
    "#        'predstore_test': trained_model['predstore_test'],\n",
    "#        'predstore_future': trained_model['predstore_future'],\n",
    "    }\n",
    "    try: \n",
    "        model['Algorithm_text'] = trained_model['Algorithm_text']\n",
    "    except:\n",
    "        print('model Algorithm_text is missing, left blank')\n",
    "    ModelList.append(model)\n",
    "    i = i + 1\n",
    "EnsembleMetaData = pd.DataFrame(ModelList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9d07a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelname</th>\n",
       "      <th>depvar</th>\n",
       "      <th>data_train</th>\n",
       "      <th>queryset</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>Algorithm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fat_baseline_rf</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>baseline</td>\n",
       "      <td>hh_fatalities_ged_ln_ultrashort</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fat_conflicthistory_rf</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>conflict_ln</td>\n",
       "      <td>fat_cm_conflict_history</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fat_conflicthistory_gbm</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>conflict_ln</td>\n",
       "      <td>fat_cm_conflict_history</td>\n",
       "      <td>GradientBoostingRegressor()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fat_conflicthistory_hurdle_lgb</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>conflict_ln</td>\n",
       "      <td>fat_cm_conflict_history</td>\n",
       "      <td>HurdleRegression(clf_name='LGBMClassifier', re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fat_conflicthistory_long_rf</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>conflictlong_ln</td>\n",
       "      <td>hh_fatalities_ged_acled_ln</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fat_vdem_hurdle_xgb</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>vdem_short</td>\n",
       "      <td>hh_fatalities_vdem_short</td>\n",
       "      <td>HurdleRegression(clf_name='XGBClassifier', reg...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fat_wdi_rf</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>wdi_short</td>\n",
       "      <td>hh_fatalities_wdi_short</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fat_topics_rf</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>topics_short</td>\n",
       "      <td>hh_topic_model_short</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fat_topics_histgbm</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>topics_short</td>\n",
       "      <td>hh_topic_model_short</td>\n",
       "      <td>HistGradientBoostingRegressor(max_iter=200)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fat_broad_xgb</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>broad</td>\n",
       "      <td>hh_broad</td>\n",
       "      <td>XGBRFRegressor(base_score=None, booster=None, ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fat_greatest_hits_hurdle_xgb</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>gh</td>\n",
       "      <td>hh_greatest_hits</td>\n",
       "      <td>HurdleRegression(clf_name='XGBClassifier', reg...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fat_hh20_hurdle_lgb</td>\n",
       "      <td>ln_ged_sb_dep</td>\n",
       "      <td>hh20</td>\n",
       "      <td>hh_20_features</td>\n",
       "      <td>HurdleRegression(clf_name='LGBMClassifier', re...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         modelname         depvar       data_train  \\\n",
       "0                  fat_baseline_rf  ln_ged_sb_dep         baseline   \n",
       "1           fat_conflicthistory_rf  ln_ged_sb_dep      conflict_ln   \n",
       "2          fat_conflicthistory_gbm  ln_ged_sb_dep      conflict_ln   \n",
       "3   fat_conflicthistory_hurdle_lgb  ln_ged_sb_dep      conflict_ln   \n",
       "4      fat_conflicthistory_long_rf  ln_ged_sb_dep  conflictlong_ln   \n",
       "5              fat_vdem_hurdle_xgb  ln_ged_sb_dep       vdem_short   \n",
       "6                       fat_wdi_rf  ln_ged_sb_dep        wdi_short   \n",
       "7                    fat_topics_rf  ln_ged_sb_dep     topics_short   \n",
       "8               fat_topics_histgbm  ln_ged_sb_dep     topics_short   \n",
       "9                    fat_broad_xgb  ln_ged_sb_dep            broad   \n",
       "10    fat_greatest_hits_hurdle_xgb  ln_ged_sb_dep               gh   \n",
       "11             fat_hh20_hurdle_lgb  ln_ged_sb_dep             hh20   \n",
       "\n",
       "                           queryset  \\\n",
       "0   hh_fatalities_ged_ln_ultrashort   \n",
       "1           fat_cm_conflict_history   \n",
       "2           fat_cm_conflict_history   \n",
       "3           fat_cm_conflict_history   \n",
       "4        hh_fatalities_ged_acled_ln   \n",
       "5          hh_fatalities_vdem_short   \n",
       "6           hh_fatalities_wdi_short   \n",
       "7              hh_topic_model_short   \n",
       "8              hh_topic_model_short   \n",
       "9                          hh_broad   \n",
       "10                 hh_greatest_hits   \n",
       "11                   hh_20_features   \n",
       "\n",
       "                                            algorithm Algorithm_text  \n",
       "0   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "1   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "2                         GradientBoostingRegressor()                 \n",
       "3   HurdleRegression(clf_name='LGBMClassifier', re...                 \n",
       "4   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "5   HurdleRegression(clf_name='XGBClassifier', reg...                 \n",
       "6   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "7   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "8         HistGradientBoostingRegressor(max_iter=200)                 \n",
       "9   XGBRFRegressor(base_score=None, booster=None, ...                 \n",
       "10  HurdleRegression(clf_name='XGBClassifier', reg...                 \n",
       "11  HurdleRegression(clf_name='LGBMClassifier', re...                 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EnsembleMetaData.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving revised model list in data frame form\n",
    "dbpath = Mydropbox + 'Projects/PredictingFatalities/Predictions/'\n",
    "filename = dbpath + 'ModelMetaData_' + dev_id\n",
    "EnsembleMetaData.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec1bfa",
   "metadata": {},
   "source": [
    "# Retrieve and calibrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1a4ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, FutureStart, run_id)\n",
    "\n",
    "ModelList = CalibratePredictions(ModelList, FutureStart, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c5f57",
   "metadata": {},
   "source": [
    "# Genetic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343bb2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed, cpu_count\n",
    "from functools import partial\n",
    "from genetic2 import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def make_run_from_step (\n",
    "    step,\n",
    "    e_set,\n",
    "    df_name = 'calib_df_calibrated', \n",
    "    target = 'ln_ged_sb_dep',\n",
    "    population_count = 100,\n",
    "    initial_population = None,\n",
    "    base_genes = np.array([0,1]),\n",
    "    number_of_generations = 500\n",
    "):\n",
    "    \"\"\"\n",
    "    step : step you want as an int,\n",
    "    ensemble_set : structure of the EnsembleList type,\n",
    "    target = Y in prediction,\n",
    "    df_name = name of the df in the ensemble set you want.\n",
    "    \"\"\"\n",
    "    \n",
    "    df_step = f'step_pred_{step}'\n",
    "    \n",
    "    try: \n",
    "        del aggregate_df\n",
    "    except NameError:\n",
    "        pass \n",
    "    \n",
    "    for i_ens in ModelList:\n",
    "        try:\n",
    "            #Join the step from the model into the ensemble df if it exists.\n",
    "            aggregate_df = aggregate_df.join(i_ens[df_name][[df_step]], rsuffix=f'_{i_ens[\"modelname\"]}')\n",
    "        except NameError:\n",
    "            #If the ensemble df does not exist create it and include the target.\n",
    "            aggregate_df = i_ens[df_name][[target,df_step]].copy()\n",
    "            aggregate_df = aggregate_df.rename(columns = {df_step : f'{df_step}_{i_ens[\"modelname\"]}'})\n",
    "    \n",
    "    aggregate_df = aggregate_df.dropna()\n",
    "    aggregate_df = aggregate_df[aggregate_df.columns[~aggregate_df.columns.str.contains('ensemble')]]\n",
    "    \n",
    "    X = aggregate_df.copy(); del X[target]\n",
    "    Y = aggregate_df[target]\n",
    "    \n",
    "    inst_mse = partial(weighted_mse_score, Y, X, mean_squared_error)\n",
    "    if initial_population is None:\n",
    "        population =  init_population_sum(population_count,base_genes,X.shape[1],0.5,3)\n",
    "    else: \n",
    "        population = initial_population\n",
    "    \n",
    "    from genetic2 import temp_file_name\n",
    "    import os\n",
    "    Path('./exploration_pickle/').mkdir(parents=True, exist_ok=True) \n",
    "    pd.DataFrame({'step':[step], 'memoization_id':[temp_file_name]}).to_csv(f'exploration_pickle/id_{temp_file_name}.csv', index=False)\n",
    "    \n",
    "    generation = genetic_algorithm(population, \n",
    "                                   inst_mse, \n",
    "                                   base_genes, \n",
    "                                   f_thres=None, \n",
    "                                   ngen=number_of_generations, \n",
    "                                   pmut=0.2)\n",
    "    return {'step':step, 'memoization_id':temp_file_name, 'generation':generation}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_walrus_genes = np.array([0, 0.001, 0.002, 0.003, 0.005, 0.007, 0.010, 0.015, 0.020, 0.025, 0.030, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.12, 0.14, 0.16, 0.18, 0.20, 0.25])\n",
    "nonlogged_genes = np.array([0, 0.02, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.9, 1, 1.1, 1.2, 1.5, 2.0])#, 1, 1.2, 1.4, 1.6, 1.8, 2.0, 2.5])\n",
    "print(len(nonlogged_genes))\n",
    "steps_to_optimize = [1,2,3,4,6,9,12,15,18,24,30,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb862d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_function = partial(make_run_from_step, \n",
    "    e_set = ModelList,\n",
    "    df_name = 'predictions_calib_df', # Non-logged version\n",
    "    target = 'ln_ged_sb_dep',\n",
    "    population_count = 100,\n",
    "    initial_population = None,\n",
    "    base_genes = super_walrus_genes,\n",
    "    number_of_generations = 500\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b415a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = cpu_count()-4 if cpu_count()>2 else 1\n",
    "cpus - len(steps_to_optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931a8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 models, 24 genes, 12 steps, 100 generations takes 41 minutes\n",
    "if RunGeneticAlgo:\n",
    "\n",
    "    ct = datetime.now()\n",
    "    print('Estimating genetic weights, current time:', ct)\n",
    "    generations = Parallel(n_jobs=cpus)(delayed(filled_function)(i) for i in steps_to_optimize)\n",
    "    ct = datetime.now()\n",
    "    print('Done estimating weights, current time:', ct)\n",
    "    with open('exploration_pickle/full_gen.pickle', 'wb') as handle:\n",
    "        pkl.dump(generations, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    picklename = 'exploration_pickle/full_gen.pickle'\n",
    "    generations = pkl.load( open (picklename, \"rb\") )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac54121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the memoization id's so that you can explore the training process in the visualizer\n",
    "for i in generations:\n",
    "    print (i['step'], i['memoization_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8cb182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the best organism.\n",
    "GeneticAlgoResult = []\n",
    "for gen in generations:\n",
    "    print ('\\nStep: ',gen['step'],'\\n','*'*24,'\\n')\n",
    "    print (gen['generation'][0])\n",
    "    #The best is always the top organism. You can get the top 20 by slicing gen['generation'][0:20] and so on\n",
    "    linedict = {\n",
    "        'Org': gen['generation'][0][0],\n",
    "        'Fitness': gen['generation'][0][1],\n",
    "        'Step': gen['step']\n",
    "    }\n",
    "    GeneticAlgoResult.append(linedict)\n",
    "print(GeneticAlgoResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475df80d",
   "metadata": {},
   "source": [
    "# Assignment of the genetic weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c20eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from GeneticAlgoResult:\n",
    "w_step = [None] * 37\n",
    "for line in GeneticAlgoResult:\n",
    "    w_step[line['Step']] = line['Org']\n",
    "i=2\n",
    "for i in [1,2,3,6,9,12,18,24,30,36]:\n",
    "    w_step[i]\n",
    "    print(sum(w_step[i]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear interpolation of weights:\n",
    "print(steps_to_optimize)\n",
    "WeightMatrix = [None] * 37\n",
    "modelnames = []\n",
    "for model in ModelList: \n",
    "    modelnames.append(model['modelname'])\n",
    "for step in steps:\n",
    "    if step in steps_to_optimize:\n",
    "#        print(step, 'is optimized')\n",
    "        WeightMatrix[step] = w_step[step]\n",
    "    else:\n",
    "        WeightMatrix[step] = np.nan * len(w_step[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f72bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepAssigner = [1,2,3,4,4,6,6,9,9,9,12,12,12,15,15,15,18,18,18,18,18,24,24,24,24,24,24,30,30,30,30,30,30,36,36,36]\n",
    "WeightMatrix = [None] * 37\n",
    "modelnames = []\n",
    "for model in ModelList: \n",
    "    modelnames.append(model['modelname'])\n",
    "\n",
    "for step in steps:\n",
    "#    print('Step',step,'assigned',StepAssigner[step-1])\n",
    "    WeightMatrix[step] = w_step[StepAssigner[step-1]]\n",
    "wmt = np.array(WeightMatrix[1:]).T\n",
    "weights_df = pd.DataFrame(wmt,columns=stepcols[1:],index=modelnames)\n",
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolated weights\n",
    "i_weights_df = weights_df.copy()\n",
    "for step in steps:\n",
    "    col = 'step_pred_' + str(step)\n",
    "    if step == 5:\n",
    "        prestepcol = 'step_pred_' + str(step-1)\n",
    "        \n",
    "        poststepcol = 'step_pred_' + str(step+1)\n",
    "        i_weights_df[col] = (i_weights_df[prestepcol] + i_weights_df[poststepcol]) / 2\n",
    "    if step == 7 or step == 10 or step == 13 or step == 16:\n",
    "        prestepcol = 'step_pred_' + str(step-1)\n",
    "        poststepcol = 'step_pred_' + str(step+2)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*2) + (i_weights_df[poststepcol]*1)) / 3\n",
    "    if step == 8 or step == 11 or step == 14 or step == 17:\n",
    "        prestepcol = 'step_pred_' + str(step-2)\n",
    "        poststepcol = 'step_pred_' + str(step+1)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*1) + (i_weights_df[poststepcol]*2)) / 3\n",
    "    if step == 19 or step == 25 or step == 31:\n",
    "        prestepcol = 'step_pred_' + str(step-1)\n",
    "        poststepcol = 'step_pred_' + str(step+5)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*5) + (i_weights_df[poststepcol]*1)) / 6\n",
    "    if step == 20 or step == 26 or step == 32:\n",
    "        prestepcol = 'step_pred_' + str(step-2)\n",
    "        poststepcol = 'step_pred_' + str(step+3)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*4) + (i_weights_df[poststepcol]*2)) / 6\n",
    "    if step == 21 or step == 27 or step == 33:\n",
    "        prestepcol = 'step_pred_' + str(step-3)\n",
    "        poststepcol = 'step_pred_' + str(step+3)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*3) + (i_weights_df[poststepcol]*3)) / 6\n",
    "    if step == 22 or step == 28 or step == 34:\n",
    "        prestepcol = 'step_pred_' + str(step-4)\n",
    "        poststepcol = 'step_pred_' + str(step+2)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*2) + (i_weights_df[poststepcol]*4)) / 6\n",
    "    if step == 23 or step == 29 or step == 35:\n",
    "        prestepcol = 'step_pred_' + str(step-5)\n",
    "        poststepcol = 'step_pred_' + str(step+1)\n",
    "        i_weights_df[col] = ((i_weights_df[prestepcol]*1) + (i_weights_df[poststepcol]*5)) / 6\n",
    "        \n",
    "print(steps_to_optimize)\n",
    "# Export weights \n",
    "i_weights_df.to_csv('GeneticWeights.csv')\n",
    "i_weights_df\n",
    "# Save the weights dfs\n",
    "dflist = [\n",
    "    (i_weights_df,'i_weights_df'), \n",
    "]\n",
    "\n",
    "path = '/Users/havardhegre/Dropbox (ViEWS)/ViEWS/Projects/PredictingFatalities/MSEs/'\n",
    "for df in dflist:\n",
    "    filename = path + df[1] + '.csv'\n",
    "    df[0].to_csv(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "palette = 'vlag'\n",
    "palette = sns.color_palette('BrBG',n_colors=50)\n",
    "palette = sns.cubehelix_palette(start=2, rot=0, dark=0, light=1, n_colors=100)\n",
    "overleafpath = '/Users/havardhegre/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Figures/Pred_Eval/'\n",
    "\n",
    "fig, ax =plt.subplots(1,figsize=(16,11))\n",
    "ax = sns.heatmap(i_weights_df, xticklabels=2, linewidths=.5, cmap=palette,square=True)\n",
    "filename = overleafpath + 'genetic_weights_exp.png'\n",
    "plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing dfs to hold the predictions\n",
    "# A list of dictionaries organizing predictions and information as one step per entry,\n",
    "# including a dataframe for each step with one column per prediction model\n",
    "StepEnsembles = []\n",
    "for col in stepcols[1:]:  # Use the baseline as template to construct object\n",
    "    Step_prediction = {\n",
    "        'step_pred': col,\n",
    "        'df_calib': pd.DataFrame(ModelList[0]['calib_df_calibrated']['ln_ged_sb_dep']), \n",
    "        'df_test': pd.DataFrame(ModelList[0]['test_df_calibrated']['ln_ged_sb_dep']),\n",
    "        'ensembles_calib': pd.DataFrame(ModelList[0]['calib_df_calibrated']['ln_ged_sb_dep']),\n",
    "        'ensembles_test': pd.DataFrame(ModelList[0]['test_df_calibrated']['ln_ged_sb_dep'])\n",
    "    }\n",
    "    for model in ModelList:\n",
    "        modelname = model['modelname']\n",
    "        Step_prediction['df_calib'][modelname] = model['calib_df_calibrated'][col]\n",
    "        Step_prediction['df_test'][modelname] = model['test_df_calibrated'][col]\n",
    "    StepEnsembles.append(Step_prediction)\n",
    "\n",
    "# Calculating unweighted average ensembles\n",
    "i = 0\n",
    "for col in stepcols[1:]:\n",
    "    # Unweighted average\n",
    "    StepEnsembles[i]['ensembles_test']['unweighted_average'] = StepEnsembles[i]['df_test'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    StepEnsembles[i]['ensembles_calib'].loc['unweighted_average'] = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da22c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepEnsembles[0]['df_test'].drop('ln_ged_sb_dep', axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10128a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "StepEnsembles[0]['ensembles_test']['unweighted_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ModelList[0]['test_df_calibrated']['ln_ged_sb_dep']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ad53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculating weighted average ensembles\n",
    "# Based on the weights_df dataframe filled with Mihai's weights above\n",
    "\n",
    "def ensemble_predictions(yhats, weights):\n",
    "    # make predictions\n",
    "    yhats = np.array(yhats)\n",
    "    # weighted sum across ensemble members\n",
    "    result = np.dot(weights,yhats)\n",
    "    return result\n",
    "\n",
    "# normalize a vector to have unit norm\n",
    "def normalize(weights):\n",
    "    # calculate l1 vector norm\n",
    "    result = norm(weights, 1)\n",
    "    # check for a vector of all zeros\n",
    "    if result == 0.0:\n",
    "        return weights\n",
    "    # return normalized vector (unit norm)\n",
    "    return weights / result\n",
    "\n",
    "i = 0\n",
    "for col in stepcols[1:]:\n",
    "    # Unweighted average\n",
    "    df_calib = StepEnsembles[i]['df_calib'].drop('ln_ged_sb_dep', axis=1)\n",
    "    df_test = StepEnsembles[i]['df_test'].drop('ln_ged_sb_dep', axis=1)\n",
    "    StepEnsembles[i]['ensembles_calib']['weighted_average'] = (df_calib*i_weights_df[col]).sum(axis=1)\n",
    "    StepEnsembles[i]['ensembles_test']['weighted_average'] =  (df_test*i_weights_df[col]).sum(axis=1)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the ensemble predictions\n",
    "EnsembleList = []\n",
    "genetic = {\n",
    "        'modelname': 'ensemble_genetic',\n",
    "        'algorithm': '',\n",
    "        'depvar': \"ln_ged_sb_dep\",\n",
    "        'calib_df_calibrated': ModelList[0]['calib_df_calibrated'].copy(),\n",
    "        'test_df_calibrated': ModelList[0]['test_df_calibrated'].copy(),\n",
    "    }    \n",
    "\n",
    "for step in StepEnsembles:\n",
    "    colname = step['step_pred']\n",
    "    print(colname)\n",
    "    genetic['calib_df_calibrated'][colname] = step['ensembles_calib']['weighted_average']\n",
    "    genetic['test_df_calibrated'][colname] = step['ensembles_test']['weighted_average']\n",
    "\n",
    "EnsembleList.append(genetic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d800259",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[12]['test_df_calibrated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ensemble predictions\n",
    "predstore_calib = level +  '_' + genetic['modelname'] + '_calib'\n",
    "genetic['calib_df_calibrated'].forecasts.set_run(run_id)\n",
    "genetic['calib_df_calibrated'].forecasts.to_store(name=predstore_calib, overwrite = True)\n",
    "predstore_test = level +  '_' + genetic['modelname'] + '_test'\n",
    "genetic['test_df_calibrated'].forecasts.set_run(run_id)\n",
    "genetic['test_df_calibrated'].forecasts.to_store(name=predstore_test, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb819703",
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic['test_df_calibrated'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305072e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ViewsMetadata().with_name('genetic').fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b92023",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97e797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
